   ________  ______  ___       ______
  / ____/ / / / __ \/   |     / ____/__    __
 / /   / / / / / / / /| |    / /  __/ /___/ /_
/ /___/ /_/ / /_/ / ___ |   / /__/_  __/_  __/
\____/\____/_____/_/  |_|   \____//_/   /_/


Introduction, Écosystème et Bonnes Pratiques
--> https://github.com/compilaction/talks/

Jules Pénuchot
--> jules@penuchot.com | @JPenuchot (Twitter/GitHub)

   - LRI, Paris-Sud: Métaprogrammation, parallélisme, métaclasses, métaparsing
   - Ste||ar Group (HPX), LSU: Blaze CUDA
   - Compilaction @ www.compilaction.com (Joël Falcou & moi-même)


--> CUDA C++, où en est l'écosystème, comment programmer efficacement ?

                                       ·
   ________  ______  ___       ______              ___
  / ____/ / / / __ \/   |     / ____/__    __     /__ \
 / /   / / / / / / / /| |    / /  __/ /___/ /_     / _/
/ /___/ /_/ / /_/ / ___ |   / /__/_  __/_  __/    /_/
\____/\____/_____/_/  |_|   \____//_/   /_/      (_)

-  "CUDA C++" est un sur-ensemble de C++ :
   -  C++ supporté dans son intégralité sur GPU (...selon le compilo)
   -  Modèle d'exécution supporté dans son intégralité sur GPU

-  GPUs = Processeurs massivement multi-coeurs & SIMD
-  Des (hyper)threads, dans des warps, dans des blocks, dans une grille
-  Warps:
   -  groupes de 32 threads (pour le moment),
   -  les threads y sont tous à la même instruction
-  Blocks:
   -  groupe de N threads assignés à un même Streaming Multiprocessor (SM)

--> Tailler ses blocks par multiples de 32!
    https://devblogs.nvidia.com/even-easier-introduction-cuda/
                                       ·
    __  __               __
   / / / /___ __________/ /      ______ _________
  / /_/ / __ `/ ___/ __  / | /| / / __ `/ ___/ _ \
 / __  / /_/ / /  / /_/ /| |/ |/ / /_/ / /  /  __/
/_/ /_/\__,_/_/   \__,_/ |__/|__/\__,_/_/   \___/

--> SM = core SIMD, pouvant exécuter 32 threads (1 warp) simultanément
    "Thread" d'un warp -> Instance "SIMD" d'un SM


- Branchement -> masquage de registres
  --> Conditions = perte de perfs! (threads en attente)
      Nécessaires dans certains cas... Mais faites des petits branchements !

- Le nombre de threads/block est limité en taille selon l'archi
  --> Volta: 128Ko de cache/shared memory par SM, max 1024 threads par block

- GPUs: + de latence, mais + de débit
  --> Volta: HBM2 900Go/s (~10x plus qu'un 2990WX, 32c/64t), NVLink 300Go/s
      https://devblogs.nvidia.com/inside-volta/
                                       ·
   _____       ______
  / ___/____  / __/ /__      ______ _________
  \__ \/ __ \/ /_/ __/ | /| / / __ `/ ___/ _ \
 ___/ / /_/ / __/ /_ | |/ |/ / /_/ / /  /  __/
/____/\____/_/  \__/ |__/|__/\__,_/_/   \___/

- Oubliez nvcc, Clang supporte CUDA C++ nativement!
  - Meilleur support de C++, de la STL, des templates...
  - Open-source (maintenu activement par Google)
  - Make & CMake: https://github.com/JPenuchot/project-templates
--> Méthode simple: rajouter `-x cuda` à Clang sur les fichiers `.cpp`

- Utilisez les algorithmes/conteneurs de Thrust...
  - API style STL (merci Bryce Lelbach)
  - Très bien optimisés pour chaque cas/archi (shared memory, shuffle, etc)
  ...et cuBLAS pour l'algèbre !

- Profiling: NSight

- Tout faire sur le GPU > Offloader au GPU (bus PCIe etc...)
                                       ·
    ____             __  _
   / __ \_________ _/ /_(_)___ ___  _____
  / /_/ / ___/ __ `/ __/ / __ `/ / / / _ \
 / ____/ /  / /_/ / /_/ / /_/ / /_/ /  __/
/_/   /_/   \__,_/\__/_/\__, /\__,_/\___/
                          /_/

- Point d'entrée - Fonctions "global": `void __global__ fun( ... ) { ... }`
  Appel: `fun <<< grid_size, block_size >>> ( ... );`
  --> Le CPU pilote des appels sur des données dans la mémoire GPU
      /!\ Ne passer que des pointeurs, itérateurs, vues, etc.

- Fonctions & lambdas `__host__ __device__` ou `constexpr` appelables sur GPU

- `cudaManagedAlloc()`: Alloue de la mémoire unifiée (Accessible via CPU & GPU)
  --> Pas besoin de `cudaMemCpy()`, géré par pagination en x86, via une fabric
      avec NVLink sous PowerPC (meilleures perfs, moins de latence, etc...)
  --> Utilisable comme allocateur pour std::vector

- `thrust::vector`, algorithmes Thrust, etc.
                                       ·
    ____                        __
   / __ \___  _________  __  __/ /___ _____ ____
  / / / / _ \/ ___/ __ \/ / / / / __ `/ __ `/ _ \
 / /_/ /  __/ /  / /_/ / /_/ / / /_/ / /_/ /  __/
/_____/\___/_/   \____/\__,_/_/\__,_/\__, /\___/
                                    /____/
Mémoire:
| 0| 1| 2| 3| 4| 5| 6| 7|

Threads 1, 2, 3 & 4, itérations 1 & 2:

i\T| 1  2  3  4
0  | 0| 1| 2| 3|
1  | 4| 5| 6| 7|
  --> Adressage contigu, OK

i\T| 1  2  3  4
0  | 0| 2| 4| 6|
1  | 1| 3| 5| 7|
  --> Adressage non contigu, PAS OK: localité mauvaise
                                       ·
  ________                    __
 /_  __/ /_  _______  _______/ /_
  / / / __ \/ ___/ / / / ___/ __/
 / / / / / / /  / /_/ (__  ) /_
/_/ /_/ /_/_/   \__,_/____/\__/

À utiliser en priorité pour ne pas écrire de kernels à la main

- thurst::generate
- thurst::generate_n
- thrust::sequence
- thrust::transform
- thrust::reduce
- thrust::...

/!\ Peut déclencher des erreurs avec clang selon les flags...

--> https://docs.nvidia.com/cuda/thrust/index.html
    Repose sur CUB: https://nvlabs.github.io/cub/
    Bonus: https://github.com/nvlabs
                                       ·
   ______                 __           _
  / ____/___  ____  _____/ /_  _______(_)___  ____
 / /   / __ \/ __ \/ ___/ / / / / ___/ / __ \/ __ \
/ /___/ /_/ / / / / /__/ / /_/ (__  ) / /_/ / / / /
\____/\____/_/ /_/\___/_/\__,_/____/_/\____/_/ /_/

Utilisez Clang !
- Compilo C++ fail-proof
- Interface simple et standard, facile à intégrer dans Make ou CMake
- Plus besoin de faire de la compilation séparée à cause de nvcc

Utilisez Thrust !
- Simple & efficace
- Inclus dans le package CUDA

Utilisez cuBLAS !
- Interface similaire à BLAS (diverge sur certains points: handles, storage)
- Utilise du PTX "secret" et les tensor cores pour gagner des perfs

--> Questions ? Illustration ?
                                       ·
